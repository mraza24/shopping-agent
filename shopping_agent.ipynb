{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oa6tZQR7Ii_4",
        "outputId": "2c6addbb-060d-458a-ec25-8c66bd71da7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/179.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m174.1/179.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.1/179.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/144.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.4/144.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# ===============================\n",
        "# Step 1: Install required packages\n",
        "# ===============================\n",
        "# openai-agents : OpenAI Agents Framework\n",
        "# openai        : OpenAI API client\n",
        "# requests      : HTTP requests to fetch product data from API endpoints\n",
        "# nest_asyncio  : Enable nested async calls in Jupyter / Colab\n",
        "%pip install --quiet openai-agents openai requests nest_asyncio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# Step 2: Import required libraries\n",
        "# ===============================\n",
        "import os\n",
        "import requests\n",
        "from getpass import getpass\n",
        "from openai import OpenAI"
      ],
      "metadata": {
        "id": "YMc47yazI1hr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# Step 3: Set OpenAI API key\n",
        "# ===============================\n",
        "# Replace with your own OpenAI API key\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass(\"🔑 Paste your OpenAI API key (starts with sk-...): \")\n",
        "print(\"✅ New API key set successfully!\")\n",
        "print(\"Key starts with:\", os.getenv(\"OPENAI_API_KEY\")[:5])  # Only first 5 characters shown for security\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFVuS9hoJGMK",
        "outputId": "2a72e263-e383-43b0-d52c-2580b06080d3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔑 Paste your OpenAI API key (starts with sk-...): ··········\n",
            "✅ New API key set successfully!\n",
            "Key starts with: sk-pr\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# Step 4: Initialize OpenAI client\n",
        "# ===============================\n",
        "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
      ],
      "metadata": {
        "id": "xzSKOwSbJaFU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# Step 5: Fetch products from API\n",
        "# ===============================\n",
        "def fetch_products():\n",
        "    \"\"\"\n",
        "    Function to fetch products from API endpoint.\n",
        "    Returns a list of products (JSON) if successful, else empty list.\n",
        "    \"\"\"\n",
        "    url = \"https://hackathon-apis.vercel.app/api/products\"  # API endpoint\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        return response.json()\n",
        "    else:\n",
        "        return []\n",
        "\n",
        "# Test fetch\n",
        "products = fetch_products()\n",
        "print(\"✅ Total products fetched:\", len(products))\n",
        "print(\"Example product:\", products[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aevuSOv0Jsea",
        "outputId": "5a4dba38-5b89-4302-8c9a-64d0cc50eba1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Total products fetched: 24\n",
            "Example product: {'name': 'The Poplar suede sofa', 'description': 'A timeless design, with premium materials features as one of our most popular and iconic pieces. The dandy chair is perfect for any stylish living space with beech legs and lambskin leather upholstery.', 'image': 'https://cdn.sanity.io/images/ri847jqu/production/9b6a4fc8c65bbb4e5793fb0e1116b510d73dc9e8-630x375.png', '_id': '65453ffd-e476-4b6b-a388-7e3de1bb632a', 'features': ['Premium material', 'Handmade upholster', 'Quality timeless classic'], 'dimensions': {'width': '110cm', 'height': '110cm', 'depth': '50cm'}, 'category': {'name': 'Tableware', 'slug': 'tableware'}, 'price': 980, 'tags': ['popular products']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# Step 6: Function to filter products\n",
        "# ===============================\n",
        "def filter_products(products, max_price=None, keyword=None):\n",
        "    \"\"\"\n",
        "    Filter products by maximum price and/or keyword in product name.\n",
        "    \"\"\"\n",
        "    results = products\n",
        "\n",
        "    if max_price:\n",
        "        results = [p for p in results if p.get(\"price\", 0) <= max_price]\n",
        "    if keyword:\n",
        "        results = [p for p in results if keyword.lower() in p.get(\"name\", \"\").lower()]\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "zhDEkir9KE79"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# Step 7: Define shopping agent query function\n",
        "# ===============================\n",
        "def shopping_agent_query(query, products):\n",
        "    \"\"\"\n",
        "    Function to interact with OpenAI model as a shopping assistant.\n",
        "    Returns AI-generated response based on product list.\n",
        "    \"\"\"\n",
        "    context = \"You are a shopping assistant. Answer based on the product list.\"\n",
        "\n",
        "    # First 10 products used as context\n",
        "    product_titles = \"\\n\".join([f\"{p['name']} - ${p['price']}\" for p in products[:10]])\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": context},\n",
        "            {\"role\": \"user\", \"content\": f\"{query}\\nHere are some products:\\n{product_titles}\"}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "Ib0wefigKQ4G"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# Step 8: Test shopping agent\n",
        "# ===============================\n",
        "query1 = \"Show me products under $300\"\n",
        "query2 = \"Find me a chair\"\n",
        "\n",
        "print(\"Query 1 Result:\\n\", shopping_agent_query(query1, products))\n",
        "print(\"\\nQuery 2 Result:\\n\", shopping_agent_query(query2, products))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njv7_E_1KahZ",
        "outputId": "75bc477a-2c78-4ba6-8773-a140c3fa6dff"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query 1 Result:\n",
            " Here are the products under $300:\n",
            "\n",
            "1. The Steel Chair - $250\n",
            "2. Rustic Vase Set - $210\n",
            "3. Bed - $250\n",
            "4. Wood Chair - $100\n",
            "5. The Lucky Lamp - $200\n",
            "6. Pure Aura - $280 (Note: This is exactly $280 and may be considered depending on your specific needs)\n",
            "7. Zen Table - $250\n",
            "\n",
            "Let me know if you need more information about any of these products!\n",
            "\n",
            "Query 2 Result:\n",
            " Here are the chairs from your product list:\n",
            "\n",
            "1. The Steel Chair - $250\n",
            "2. Wood Chair - $100\n",
            "\n",
            "You can choose between the Steel Chair or the Wood Chair based on your preference!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g3KdvaKwKqT4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}